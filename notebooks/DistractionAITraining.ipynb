{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e16865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761021922.885679   16147 port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "I0000 00:00:1761021922.917793   16147 cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761021924.296525   16147 port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: 2.21.0-dev20251017\n",
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1761021925.708708   16147 gpu_device.cc:2456] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b541b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c864e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary packages \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D,Conv2D,Dense,Dropout,Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33aa195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the data paths\n",
    "\n",
    "base_dir = '' # base directory  \n",
    "train_dir = os.path.join(base_dir,'/home/lurpd/Development/Datasets/DistractedDriverSet/imgs/train/')              # train directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ecb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_def = {\n",
    "    'c0': 'Safe driving', \n",
    "    'c1': 'Distracted',\n",
    "    'c2': 'Tired', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91dd3d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add random letterboxing to trainng \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def random_letterbox(img_array):\n",
    "    #convert numpy array back to PIL for easier manipulation    \n",
    "    if img_array.ndim == 3 and img_array.shape[-1] == 1:\n",
    "        img_array = np.squeeze(img_array, axis=-1)\n",
    "\n",
    "    img = Image.fromarray(np.uint8(img_array))\n",
    "    target_size = (128, 128)\n",
    "    \n",
    "    #random scale factor \n",
    "    scale = np.random.uniform(0.8, 1.0)\n",
    "    \n",
    "    new_w = int(target_size[0] * scale)\n",
    "    new_h = int(target_size[1] * scale)\n",
    "    \n",
    "    img = img.resize((new_w, new_h), Image.Resampling.LANCZOS)\n",
    "    \n",
    "    #black background\n",
    "    background = Image.new(\"L\", target_size, 0)\n",
    "    \n",
    "    #center in the frame\n",
    "    x_offset = (target_size[0] - new_w) // 2\n",
    "    y_offset = (target_size[1] - new_h) // 2\n",
    "    \n",
    "    background.paste(img, (x_offset, y_offset))\n",
    "    \n",
    "    #convert back to numpy float array\n",
    "    arr = np.array(background).astype(np.float32)\n",
    "    arr = np.expand_dims(arr, axis=-1)\n",
    "    return arr / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01468b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (128,128)  # image shape\n",
    "batch_size = 64\n",
    "val_size = 0.2\n",
    "\n",
    "#data augmentations for better generalizing\n",
    "train_data_gen = ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    preprocessing_function=random_letterbox,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_data_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e93bc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31436 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1761021925.910905   16147 gpu_device.cc:2456] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7857 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761021926.008928   16147 gpu_device.cc:2040] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9129 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5070, pci bus id: 0000:01:00.0, compute capability: 12.0a\n"
     ]
    }
   ],
   "source": [
    "# defining the training parameters\n",
    "\n",
    "\n",
    "train_generator = train_data_gen.flow_from_directory(train_dir,\n",
    "                                                     target_size = image_size,\n",
    "                                                     batch_size = batch_size,\n",
    "                                                     seed=42, \n",
    "                                                     shuffle=True,\n",
    "                                                     subset='training',\n",
    "                                                     color_mode='grayscale')\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 128, 128, 1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, train_generator.num_classes), dtype=tf.float32)\n",
    "    )\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_generator =  train_data_gen.flow_from_directory(train_dir,\n",
    "                                               target_size = image_size,\n",
    "                                               batch_size = batch_size,\n",
    "                                               seed=42, \n",
    "                                               shuffle=True,\n",
    "                                               subset='validation',\n",
    "                                               color_mode='grayscale')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73cc4afa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_PrefetchDataset' object has no attribute 'classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m class_counts = collections.Counter(\u001b[43mtrain_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses\u001b[49m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m, count \u001b[38;5;129;01min\u001b[39;00m class_counts.items():\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(train_generator.class_indices.keys())[\u001b[38;5;28mcls\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: '_PrefetchDataset' object has no attribute 'classes'"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "class_counts = collections.Counter(train_generator.classes)\n",
    "for cls, count in class_counts.items():\n",
    "    print(f\"{cls} ({list(train_generator.class_indices.keys())[cls]}): {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ed60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_batch,label_batch in train_generator:\n",
    "    print(data_batch.shape)   # train batch\n",
    "    print(label_batch.shape)  # label batch\n",
    "    break\n",
    "\n",
    "batch_x, batch_y = next(train_generator)\n",
    "print(batch_x.shape, batch_x.min(), batch_x.max())\n",
    "plt.imshow(batch_x[0].squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400d873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dropout\n",
    "\n",
    "class CPUDropout(Dropout):\n",
    "    def call(self, inputs, training=None):\n",
    "        with tf.device('/CPU:0'):\n",
    "            return super().call(inputs, training=training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44699908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,1)),\n",
    "    MaxPooling2D(2,2),\n",
    "    CPUDropout(0.3),\n",
    "\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    CPUDropout(0.3),\n",
    "\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    CPUDropout(0.4),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    CPUDropout(0.5),\n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab531a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda6870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#autocalculate class weight\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "import collections\n",
    "\n",
    "class_counts = collections.Counter(train_generator.classes)\n",
    "\n",
    "print(\"\\nImage count per class:\")\n",
    "for class_index, count in sorted(class_counts.items()):\n",
    "    class_name = list(train_generator.class_indices.keys())[class_index]\n",
    "    print(f\"  {class_index} ({class_name}): {count} images\")\n",
    "\n",
    "class_indices = train_generator.class_indices\n",
    "num_classes = len(class_indices)\n",
    "class_labels = np.unique(train_generator.classes)\n",
    "\n",
    "weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=class_labels,\n",
    "    y=train_generator.classes\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(weights))\n",
    "\n",
    "#print to make sure\n",
    "print(\"\\nAuto-calculated class weights:\")\n",
    "for i, w in class_weights.items():\n",
    "    class_name = list(class_indices.keys())[i]\n",
    "    print(f\"  {i} ({class_name}): {w:.3f}\")\n",
    "\n",
    "# manual weights just in case\n",
    "class_weights = {\n",
    "    0: 1.2,  #Safe driving\n",
    "    1: 0.5,  #distracted\n",
    "    2: 0.0,  #tired\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3888225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    class_weight=class_weights,\n",
    "    # callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65c5ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"distracted_driver_detection.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b43a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_loss = history.history['loss']\n",
    "tr_accuracy = history.history['accuracy']\n",
    "\n",
    "val_loss = history.history['val_loss']\n",
    "val_accuracy = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9908ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "epchs = list(range(1,len(tr_loss)+1))\n",
    "plt.plot(epchs,tr_loss,label='Train')\n",
    "plt.plot(epchs,val_loss,label='Test')\n",
    "plt.title(\"Training and Validation loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(epchs,tr_accuracy,label='Train')\n",
    "plt.plot(epchs,val_accuracy,label='Test')\n",
    "plt.title(\"Training and Validation accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c14315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model with real data\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import math\n",
    "\n",
    "# load model\n",
    "model = load_model(\"distracted_driver_detection.keras\",\n",
    "                   custom_objects={\"CPUDropout\": Dropout})\n",
    "\n",
    "# class names\n",
    "class_names = [\"Safe driving\", \"Distracted\", \"Tired\"]\n",
    "\n",
    "# folder\n",
    "folder = \"/home/lurpd/Development/Datasets/MyData/\"\n",
    "target_size = (128, 128)\n",
    "\n",
    "image_paths = []\n",
    "for i in range(30, 63):\n",
    "    for ext in [\".png\", \".PNG\", \".jpg\", \".JPG\", \".jpeg\", \".JPEG\"]:\n",
    "        candidate = os.path.join(folder, f\"{i}{ext}\")\n",
    "        if os.path.exists(candidate):\n",
    "            image_paths.append(candidate)\n",
    "            break  \n",
    "\n",
    "# display grid\n",
    "cols = 8\n",
    "rows = math.ceil(len(image_paths) / cols)\n",
    "max_width_px = 2500\n",
    "max_height_px = 1300\n",
    "dpi = 100\n",
    "fig_width = min(max_width_px / dpi, cols * 3)\n",
    "fig_height = min(max_height_px / dpi, rows * 3)\n",
    "plt.figure(figsize=(fig_width, fig_height), dpi=dpi)\n",
    "\n",
    "# process/display each image\n",
    "for idx, img_path in enumerate(image_paths):\n",
    "    img = Image.open(img_path).convert(\"L\")\n",
    "    img = ImageOps.pad(img, target_size, color=0, method=Image.Resampling.LANCZOS)\n",
    "    img_array = np.expand_dims(np.array(img).astype(np.float32) / 255.0, axis=(0, -1))\n",
    "\n",
    "    # predict\n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_label = class_names[predicted_class]\n",
    "    confidence = np.max(predictions) * 100\n",
    "\n",
    "    # display\n",
    "    plt.subplot(rows, cols, idx + 1)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.text(\n",
    "        0.5, -0.05,\n",
    "        f\"{os.path.basename(img_path)}\\n{predicted_label} ({confidence:.1f}%)\",\n",
    "        fontsize=9,\n",
    "        ha=\"center\", va=\"top\",\n",
    "        transform=plt.gca().transAxes\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.draw()\n",
    "\n",
    "# save automatically\n",
    "output_path = \"predictions_grid.png\"\n",
    "plt.savefig(output_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"✅ Saved predictions grid to {output_path}\")\n",
    "\n",
    "# open automatically (works in WSL or native Linux)\n",
    "try:\n",
    "    if os.path.exists(\"/mnt/c/Windows\"):\n",
    "        os.system(f\"explorer.exe {output_path.replace('/', '\\\\\\\\')}\")\n",
    "    else:\n",
    "        os.system(f\"xdg-open {output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not auto-open image: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
