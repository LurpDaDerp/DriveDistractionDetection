{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b541b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c864e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary packages \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D,Conv2D,Dense,Dropout,Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the data paths\n",
    "\n",
    "base_dir = '' # base directory  \n",
    "train_dir = os.path.join(base_dir,'//wsl.localhost/Ubuntu/home/lurpd/Development/Datasets/DistractedDriverSet/imgs/train/')              # train directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ecb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_def = {\n",
    "    'c0': 'Safe driving', \n",
    "    'c1': 'Distracted',\n",
    "    'c2': 'Tired', \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dd3d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add random letterboxing to trainng \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def random_letterbox(img_array):\n",
    "    #convert numpy array back to PIL for easier manipulation    \n",
    "    if img_array.ndim == 3 and img_array.shape[-1] == 1:\n",
    "        img_array = np.squeeze(img_array, axis=-1)\n",
    "\n",
    "    img = Image.fromarray(np.uint8(img_array))\n",
    "    target_size = (128, 128)\n",
    "    \n",
    "    #random scale factor \n",
    "    scale = np.random.uniform(0.8, 1.0)\n",
    "    \n",
    "    new_w = int(target_size[0] * scale)\n",
    "    new_h = int(target_size[1] * scale)\n",
    "    \n",
    "    img = img.resize((new_w, new_h), Image.Resampling.LANCZOS)\n",
    "    \n",
    "    #black background\n",
    "    background = Image.new(\"L\", target_size, 0)\n",
    "    \n",
    "    #center in the frame\n",
    "    x_offset = (target_size[0] - new_w) // 2\n",
    "    y_offset = (target_size[1] - new_h) // 2\n",
    "    \n",
    "    background.paste(img, (x_offset, y_offset))\n",
    "    \n",
    "    #convert back to numpy float array\n",
    "    arr = np.array(background).astype(np.float32)\n",
    "    arr = np.expand_dims(arr, axis=-1)\n",
    "    return arr / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01468b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (128,128)  # image shape\n",
    "batch_size = 32\n",
    "val_size = 0.2\n",
    "\n",
    "#data augmentations for better generalizing\n",
    "train_data_gen = ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    preprocessing_function=random_letterbox,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_data_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e93bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the training parameters\n",
    "\n",
    "\n",
    "train_generator = train_data_gen.flow_from_directory(train_dir,\n",
    "                                                     target_size = image_size,\n",
    "                                                     batch_size = batch_size,\n",
    "                                                     seed=42, \n",
    "                                                     shuffle=True,\n",
    "                                                     subset='training',\n",
    "                                                     color_mode='grayscale')\n",
    "\n",
    "val_generator =  train_data_gen.flow_from_directory(train_dir,\n",
    "                                               target_size = image_size,\n",
    "                                               batch_size = batch_size,\n",
    "                                               seed=42, \n",
    "                                               shuffle=True,\n",
    "                                               subset='validation',\n",
    "                                               color_mode='grayscale')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cc4afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class_counts = collections.Counter(train_generator.classes)\n",
    "for cls, count in class_counts.items():\n",
    "    print(f\"{cls} ({list(train_generator.class_indices.keys())[cls]}): {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ed60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_batch,label_batch in train_generator:\n",
    "    print(data_batch.shape)   # train batch\n",
    "    print(label_batch.shape)  # label batch\n",
    "    break\n",
    "\n",
    "batch_x, batch_y = next(train_generator)\n",
    "print(batch_x.shape, batch_x.min(), batch_x.max())\n",
    "plt.imshow(batch_x[0].squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44699908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,1)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary() #print summary of model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab531a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda6870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#autocalculate class weight\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "import collections\n",
    "\n",
    "class_counts = collections.Counter(train_generator.classes)\n",
    "\n",
    "print(\"\\nImage count per class:\")\n",
    "for class_index, count in sorted(class_counts.items()):\n",
    "    class_name = list(train_generator.class_indices.keys())[class_index]\n",
    "    print(f\"  {class_index} ({class_name}): {count} images\")\n",
    "\n",
    "class_indices = train_generator.class_indices\n",
    "num_classes = len(class_indices)\n",
    "class_labels = np.unique(train_generator.classes)\n",
    "\n",
    "weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=class_labels,\n",
    "    y=train_generator.classes\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(weights))\n",
    "\n",
    "#print to make sure\n",
    "print(\"\\nAuto-calculated class weights:\")\n",
    "for i, w in class_weights.items():\n",
    "    class_name = list(class_indices.keys())[i]\n",
    "    print(f\"  {i} ({class_name}): {w:.3f}\")\n",
    "\n",
    "# manual weights just in case\n",
    "class_weights = {\n",
    "    0: 1.2,  #Safe driving\n",
    "    1: 0.8,  #distracted\n",
    "    2: 2.0,  #tired\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3888225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65c5ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"distracted_driver_detection.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b43a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_loss = history.history['loss']\n",
    "tr_accuracy = history.history['accuracy']\n",
    "\n",
    "val_loss = history.history['val_loss']\n",
    "val_accuracy = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9908ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "epchs = list(range(1,len(tr_loss)+1))\n",
    "plt.plot(epchs,tr_loss,label='Train')\n",
    "plt.plot(epchs,val_loss,label='Test')\n",
    "plt.title(\"Training and Validation loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(epchs,tr_accuracy,label='Train')\n",
    "plt.plot(epchs,val_accuracy,label='Test')\n",
    "plt.title(\"Training and Validation accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
